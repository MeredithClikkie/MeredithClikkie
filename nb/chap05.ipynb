{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeredithClikkie/MeredithClikkie/blob/main/nb/chap05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418e407e",
      "metadata": {
        "id": "418e407e"
      },
      "source": [
        "The third edition of *Think Stats* is available now from [Bookshop.org](https://bookshop.org/a/98697/9781098190255) and [Amazon](https://amzn.to/42lmxwu) (those are affiliate links). If you are enjoying the free, online version, consider [buying me a coffee](https://buymeacoffee.com/allendowney)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c3b5200",
      "metadata": {
        "id": "6c3b5200"
      },
      "source": [
        "# Modeling Distributions\n",
        "\n",
        "The distributions we have used so far are called empirical distributions because they are based on empirical observations -- in other words, data. Many datasets we see in the real world can be closely approximated by a theoretical distribution, which is usually based on a simple mathematical function. This chapter presents some of these theoretical distributions and datasets they can be used to model.\n",
        "\n",
        "As examples, we'll see that:\n",
        "\n",
        "*    In a skeet shooting competition, the number of hits and misses is well modeled by a binomial distribution.\n",
        "\n",
        "*    In games like hockey and soccer (football), the number of goals in a game follows a Poisson distribution, and the time between goals follows an exponential distribution.\n",
        "\n",
        "*    Birth weights follow a normal distribution, also called a Gaussian, and adult weights follow a lognormal distribution.\n",
        "\n",
        "If you are not familiar with these distributions -- or these sports -- I will explain what you need to know. For each example, we'll start with a simulation based on a simple model, and show that the simulation results follow a theoretical distribution. Then we'll see how well real data agrees with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b65bb81",
      "metadata": {
        "tags": [],
        "id": "5b65bb81"
      },
      "source": [
        "[Click here to run this notebook on Colab](https://colab.research.google.com/github/AllenDowney/ThinkStats/blob/v3/nb/chap05.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "41ffa5f5",
      "metadata": {
        "tags": [],
        "id": "41ffa5f5",
        "outputId": "2c7db853-60aa-4b26-992b-52f5a289013b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded thinkstats.py\n"
          ]
        }
      ],
      "source": [
        "from os.path import basename, exists\n",
        "\n",
        "\n",
        "def download(url):\n",
        "    filename = basename(url)\n",
        "    if not exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print(\"Downloaded \" + local)\n",
        "\n",
        "\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52938742",
      "metadata": {
        "tags": [],
        "id": "52938742",
        "outputId": "015d6b3c-deeb-4a4f-dbd2-e9ba8e2731f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting empiricaldist\n",
            "  Downloading empiricaldist-0.9.0.tar.gz (14 kB)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import empiricaldist\n",
        "except ImportError:\n",
        "    %pip install empiricaldist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb94810",
      "metadata": {
        "tags": [],
        "id": "9fb94810"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from thinkstats import decorate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5887c412",
      "metadata": {
        "id": "5887c412"
      },
      "source": [
        "## The Binomial Distribution\n",
        "\n",
        "As a first example, we'll consider the sport of skeet shooting, in which competitors use shotguns to shoot clay disks that are thrown into the air.\n",
        "In international competition, including the Olympics, there are five rounds with 25 targets per round, with additional rounds as needed to determine a winner.\n",
        "\n",
        "As a model of a skeet-shooting competition, suppose that every participant has the same probability, `p`, of hitting every target.\n",
        "Of course, this model is a simplification -- in reality, some competitors have a higher probability than others, and even for a single competitor, it might vary from one attempt to the next.\n",
        "But even if it is not realistic, this model makes some surprisingly accurate predictions, as we'll see.\n",
        "\n",
        "To simulate the model, I'll use the following function, which takes the number of targets, `n`, and the probability of hitting each one, `p`, and returns a sequence of 1s and 0s to indicate hits and misses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e420cb7",
      "metadata": {
        "id": "3e420cb7"
      },
      "outputs": [],
      "source": [
        "def flip(n, p):\n",
        "    choices = [1, 0]\n",
        "    probs = [p, 1 - p]\n",
        "    return np.random.choice(choices, n, p=probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d721838",
      "metadata": {
        "id": "6d721838"
      },
      "source": [
        "Here's an example that simulates a round of 25 targets where the probability of hitting each one is 90%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3403ca3",
      "metadata": {
        "tags": [],
        "id": "e3403ca3"
      },
      "outputs": [],
      "source": [
        "# Seed the random number generator so we get the same results every time\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747c1000",
      "metadata": {
        "id": "747c1000"
      },
      "outputs": [],
      "source": [
        "flip(25, 0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529dc6a2",
      "metadata": {
        "id": "529dc6a2"
      },
      "source": [
        "If we generate a longer sequence and compute the `Pmf` of the results, we can confirm that the proportions of 1s and 0s are correct, at least approximately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4a9c2a",
      "metadata": {
        "id": "bd4a9c2a"
      },
      "outputs": [],
      "source": [
        "from empiricaldist import Pmf\n",
        "\n",
        "seq = flip(1000, 0.9)\n",
        "pmf = Pmf.from_seq(seq)\n",
        "pmf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a62858",
      "metadata": {
        "id": "28a62858"
      },
      "source": [
        "Now we can use `flip` to simulate a round of skeet shooting and return the number of hits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ad325e",
      "metadata": {
        "id": "67ad325e"
      },
      "outputs": [],
      "source": [
        "def simulate_round(n, p):\n",
        "    seq = flip(n, p)\n",
        "    return seq.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2a95d7",
      "metadata": {
        "id": "ea2a95d7"
      },
      "source": [
        "In a large competition, suppose 200 competitors shoot 5 rounds each, all with the same probability of hitting the target, `p=0.9`.\n",
        "We can simulate a competition like that by calling `simulate_round` 1000 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b515d45e",
      "metadata": {
        "id": "b515d45e"
      },
      "outputs": [],
      "source": [
        "n = 25\n",
        "p = 0.9\n",
        "results_sim = [simulate_round(n, p) for i in range(1000)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2d07a13",
      "metadata": {
        "id": "d2d07a13"
      },
      "source": [
        "The average score is close to `22.5`, which is the product of `n` and `p`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2e833c",
      "metadata": {
        "id": "dd2e833c"
      },
      "outputs": [],
      "source": [
        "np.mean(results_sim), n * p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d4d2ebf",
      "metadata": {
        "id": "5d4d2ebf"
      },
      "source": [
        "Here's what the distribution of the results looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9814c2",
      "metadata": {
        "id": "7c9814c2"
      },
      "outputs": [],
      "source": [
        "from empiricaldist import Pmf\n",
        "\n",
        "pmf_sim = Pmf.from_seq(results_sim, name=\"simulation results\")\n",
        "\n",
        "pmf_sim.bar()\n",
        "decorate(xlabel=\"Hits\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c498948",
      "metadata": {
        "id": "5c498948"
      },
      "source": [
        "The peak is near the mean, and the distribution is skewed to the left.\n",
        "\n",
        "Instead of running a simulation, we could have predicted this distribution.\n",
        "Mathematically, the distribution of these outcomes follows a **binomial distribution**, which has a PMF that is easy to compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3b479d",
      "metadata": {
        "id": "5f3b479d"
      },
      "outputs": [],
      "source": [
        "from scipy.special import comb\n",
        "\n",
        "\n",
        "def binomial_pmf(k, n, p):\n",
        "    return comb(n, k) * (p**k) * ((1 - p) ** (n - k))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba15dee8",
      "metadata": {
        "id": "ba15dee8"
      },
      "source": [
        "SciPy provides the `comb` function, which computes the number of combinations of `n` things taken `k` at a time, often pronounced \"n choose k\".\n",
        "\n",
        "`binomial_pmf` computes the probability of getting `k` hits out of `n` attempts, given `p`.\n",
        "If we call this function with a range of `k` values, we can make a `Pmf` that represents the distribution of the outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9590e8cc",
      "metadata": {
        "id": "9590e8cc"
      },
      "outputs": [],
      "source": [
        "ks = np.arange(16, n + 1)\n",
        "ps = binomial_pmf(ks, n, p)\n",
        "pmf_binom = Pmf(ps, ks, name=\"binomial model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b735403",
      "metadata": {
        "id": "5b735403"
      },
      "source": [
        "And here's what it looks like compared to the simulation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4138df",
      "metadata": {
        "id": "7a4138df"
      },
      "outputs": [],
      "source": [
        "from thinkstats import two_bar_plots\n",
        "\n",
        "two_bar_plots(pmf_sim, pmf_binom)\n",
        "decorate(xlabel=\"Hits\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7879e5af",
      "metadata": {
        "id": "7879e5af"
      },
      "source": [
        "They are similar, with small differences because of random variation in the simulation results.\n",
        "This agreement should not be surprising, because the simulation and the model are based on the same assumptions -- particularly the assumption that every attempt has the same probability of success.\n",
        "A stronger test of a model is how it compares to real data.\n",
        "\n",
        "From the Wikipedia page for the men's skeet shooting competition at the 2020 Summer Olympics, we can extract a table that shows the results for the qualification rounds.\n",
        "Instructions for downloading the data are in the notebook for this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d724e0ed",
      "metadata": {
        "tags": [],
        "id": "d724e0ed"
      },
      "source": [
        "Downloaded from <https://en.wikipedia.org/wiki/Shooting_at_the_2020_Summer_Olympics_–_Men's_skeet> on July 15, 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2017a1bc",
      "metadata": {
        "id": "2017a1bc"
      },
      "outputs": [],
      "source": [
        "filename = \"Shooting_at_the_2020_Summer_Olympics_Mens_skeet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b5831c",
      "metadata": {
        "tags": [],
        "id": "86b5831c"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/\" + filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f462d5",
      "metadata": {
        "id": "80f462d5"
      },
      "outputs": [],
      "source": [
        "tables = pd.read_html(filename)\n",
        "table = tables[6]\n",
        "table.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc26901",
      "metadata": {
        "id": "ecc26901"
      },
      "source": [
        "The table has one row for each competitor, with one column for each of five rounds.\n",
        "We'll select the columns that contain these results and use the NumPy function `flatten` to put them into a single array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58108620",
      "metadata": {
        "id": "58108620"
      },
      "outputs": [],
      "source": [
        "columns = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "results = table[columns].values.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6961ed",
      "metadata": {
        "id": "1a6961ed"
      },
      "source": [
        "With 30 competitors, we have results from 150 rounds of 25 shots each, with 3750 hits out of a total of 3575 attempts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0798664f",
      "metadata": {
        "id": "0798664f"
      },
      "outputs": [],
      "source": [
        "total_shots = 25 * len(results)\n",
        "total_hits = results.sum()\n",
        "n, total_shots, total_hits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bfbd3a3",
      "metadata": {
        "id": "3bfbd3a3"
      },
      "source": [
        "So the overall success rate is 95.3%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c54715",
      "metadata": {
        "id": "d9c54715"
      },
      "outputs": [],
      "source": [
        "p = total_hits / total_shots\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0081ed3b",
      "metadata": {
        "id": "0081ed3b"
      },
      "source": [
        "Now let's compute a `Pmf` that represents the binomial distribution with `n=25` and the value of `p` we just computed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e936f800",
      "metadata": {
        "id": "e936f800"
      },
      "outputs": [],
      "source": [
        "ps = binomial_pmf(ks, n, p)\n",
        "pmf_binom = Pmf(ps, ks, name=\"binomial model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83ed3fd",
      "metadata": {
        "id": "a83ed3fd"
      },
      "source": [
        "And we can compare that to the `Pmf` of the actual results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee862bb0",
      "metadata": {
        "id": "ee862bb0"
      },
      "outputs": [],
      "source": [
        "pmf_results = Pmf.from_seq(results, name=\"actual results\")\n",
        "\n",
        "two_bar_plots(pmf_results, pmf_binom)\n",
        "decorate(xlabel=\"Hits\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb98f9e9",
      "metadata": {
        "id": "fb98f9e9"
      },
      "source": [
        "The binomial model is a good fit for the distribution of the data -- even though it makes the unrealistic assumption that all competitors have the same, unchanging capability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2410330",
      "metadata": {
        "id": "c2410330"
      },
      "source": [
        "## The Poisson Distribution\n",
        "\n",
        "As another example where the outcomes of sports events follow predictable patterns, let's look at the number of goals scored in ice hockey games.\n",
        "\n",
        "We'll start by simulating a 60-minute game, which is 3600 seconds, assuming that the teams score a total of 6 goals per game, on average, and that the goal-scoring probability, `p`,  is the same during any second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600e86a5",
      "metadata": {
        "id": "600e86a5"
      },
      "outputs": [],
      "source": [
        "n = 3600\n",
        "m = 6\n",
        "p = m / 3600\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc6fbab",
      "metadata": {
        "id": "1dc6fbab"
      },
      "source": [
        "Now we can use the following function to simulate `n` seconds and return the total number of goals scored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90168872",
      "metadata": {
        "id": "90168872"
      },
      "outputs": [],
      "source": [
        "def simulate_goals(n, p):\n",
        "    return flip(n, p).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88b25ae",
      "metadata": {
        "id": "d88b25ae"
      },
      "source": [
        "If we simulate many games, we can confirm that the average number of goals per game is close to 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0cb6428",
      "metadata": {
        "id": "b0cb6428"
      },
      "outputs": [],
      "source": [
        "goals = [simulate_goals(n, p) for i in range(1001)]\n",
        "np.mean(goals)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba8f3af",
      "metadata": {
        "id": "bba8f3af"
      },
      "source": [
        "We could use the binomial distribution to model these results, but when `n` is large and `p` is small, the results are also well-modeled by a **Poisson distribution**, which is specified by a value usually denoted with the Greek letter λ, which is pronounced \"lambda\" and represented in code with the variable `lam` (`lambda` is not a legal variable name because it is a Python keyword).\n",
        "`lam` represents the goal-scoring rate, which is 6 goals per game in the example.\n",
        "\n",
        "The PMF of the Poisson distribution is easy to compute -- given `lam`, we can use the following function to compute the probability of seeing `k` goals in a game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f02db715",
      "metadata": {
        "id": "f02db715"
      },
      "outputs": [],
      "source": [
        "from scipy.special import factorial\n",
        "\n",
        "\n",
        "def poisson_pmf(k, lam):\n",
        "    \"\"\"Compute the Poisson PMF.\n",
        "\n",
        "    k (int or array-like): The number of occurrences\n",
        "    lam (float): The rate parameter (λ) of the Poisson distribution\n",
        "\n",
        "    returns: float or ndarray\n",
        "    \"\"\"\n",
        "    return (lam**k) * np.exp(-lam) / factorial(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af07cfc",
      "metadata": {
        "id": "4af07cfc"
      },
      "source": [
        "SciPy provides the `factorial` function, which computes the product of the integers from `1` to `k`.\n",
        "\n",
        "If we call `poisson_pmf` with a range of `k` values, we can make a `Pmf` that represents the distribution of outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ba8513",
      "metadata": {
        "id": "f8ba8513"
      },
      "outputs": [],
      "source": [
        "lam = 6\n",
        "ks = np.arange(20)\n",
        "ps = poisson_pmf(ks, lam)\n",
        "pmf_poisson = Pmf(ps, ks, name=\"Poisson model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d740db17",
      "metadata": {
        "id": "d740db17"
      },
      "source": [
        "And confirm that the mean of the distribution is close to 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b22d566",
      "metadata": {
        "id": "2b22d566"
      },
      "outputs": [],
      "source": [
        "pmf_poisson.normalize()\n",
        "pmf_poisson.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4c0728",
      "metadata": {
        "id": "3a4c0728"
      },
      "source": [
        "The following figure compares the results from the simulation to the Poisson distribution with the same mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8231e5fd",
      "metadata": {
        "id": "8231e5fd"
      },
      "outputs": [],
      "source": [
        "pmf_sim = Pmf.from_seq(goals, name=\"simulation\")\n",
        "\n",
        "two_bar_plots(pmf_sim, pmf_poisson)\n",
        "decorate(xlabel=\"Goals\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2958fdf4",
      "metadata": {
        "id": "2958fdf4"
      },
      "source": [
        "The distributions are similar except for small differences due to random variation.\n",
        "That should not be surprising, because the simulation and the Poisson model are based on the same assumption that the probability of scoring a goal is the same during any second of the game.\n",
        "So a stronger test is to see how well the model fits real data.\n",
        "\n",
        "From HockeyReference, I downloaded results of every game of the National Hockey League (NHL) 2023-2024 regular season (not including the playoffs).\n",
        "I extracted information about goals scored during 60 minutes of regulation play, not including overtime or tie-breaking shootouts.\n",
        "The results are in an HDF file with one key for each game, and a list of times, in seconds since the beginning of the game, when a goal was scored.\n",
        "Instructions for downloading the data are in the notebook for this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eda870bc",
      "metadata": {
        "tags": [],
        "id": "eda870bc"
      },
      "source": [
        "Raw data downloaded from <https://www.hockey-reference.com/leagues/NHL_2024_games.html> on July 16, 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184ee75f",
      "metadata": {
        "tags": [],
        "id": "184ee75f"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/nhl_2023_2024.hdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95e2f638",
      "metadata": {
        "id": "95e2f638"
      },
      "source": [
        "Here's how we read the keys from the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2c9ae5",
      "metadata": {
        "id": "4b2c9ae5"
      },
      "outputs": [],
      "source": [
        "filename = \"nhl_2023_2024.hdf\"\n",
        "\n",
        "with pd.HDFStore(filename, \"r\") as store:\n",
        "    keys = store.keys()\n",
        "\n",
        "len(keys), keys[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559cbeb6",
      "metadata": {
        "id": "559cbeb6"
      },
      "source": [
        "There were 1312 games during the regular season.\n",
        "Each key contains the date of the game and a three-letter abbreviation for the home team.\n",
        "We can use `read_hdf` to look up a key and get the list of times when a goal was scored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39108c7",
      "metadata": {
        "id": "b39108c7"
      },
      "outputs": [],
      "source": [
        "times = pd.read_hdf(filename, key=keys[0])\n",
        "times"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd132503",
      "metadata": {
        "id": "fd132503"
      },
      "source": [
        "In the first game of the season, six goals were scored, the first after 424 seconds of play, the last after 3513 seconds -- with only 87 seconds left in the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a54906",
      "metadata": {
        "tags": [],
        "id": "32a54906"
      },
      "outputs": [],
      "source": [
        "3600 - times[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99919d66",
      "metadata": {
        "id": "99919d66"
      },
      "source": [
        "The following loop reads the results for all games, counts the number of goals in each one, and stores the results in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffcf3dfd",
      "metadata": {
        "id": "ffcf3dfd"
      },
      "outputs": [],
      "source": [
        "goals = []\n",
        "\n",
        "for key in keys:\n",
        "    times = pd.read_hdf(filename, key=key)\n",
        "    n = len(times)\n",
        "    goals.append(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d84dd07",
      "metadata": {
        "id": "1d84dd07"
      },
      "source": [
        "The average number of goals per game is just over 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6ab6bc",
      "metadata": {
        "id": "4f6ab6bc"
      },
      "outputs": [],
      "source": [
        "lam = np.mean(goals)\n",
        "lam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61ec268",
      "metadata": {
        "id": "b61ec268"
      },
      "source": [
        "We can use `poisson_pmf` to make a `Pmf` that represents a Poisson distribution with the same mean as the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bec1ba",
      "metadata": {
        "id": "b5bec1ba"
      },
      "outputs": [],
      "source": [
        "ps = poisson_pmf(ks, lam)\n",
        "pmf_poisson = Pmf(ps, ks, name=\"Poisson model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb748573",
      "metadata": {
        "id": "bb748573"
      },
      "source": [
        "And here's what it looks like compared to the PMF of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e97704a1",
      "metadata": {
        "id": "e97704a1"
      },
      "outputs": [],
      "source": [
        "pmf_goals = Pmf.from_seq(goals, name=\"goals scored\")\n",
        "\n",
        "two_bar_plots(pmf_goals, pmf_poisson)\n",
        "decorate(xlabel=\"Goals\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fac89a4",
      "metadata": {
        "id": "6fac89a4"
      },
      "source": [
        "The Poisson distribution fits the data well, which suggests that it is a good model of the goal-scoring process in hockey."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c50c6fc5",
      "metadata": {
        "id": "c50c6fc5"
      },
      "source": [
        "## The Exponential Distribution\n",
        "\n",
        "In the previous section, we simulated a simple model of a hockey game where a goal has the same probability of being scored during any second of the game.\n",
        "Under the same model, it turns out, the time until the first goal follows an **exponential distribution**.\n",
        "\n",
        "To demonstrate, let's assume again that the teams score a total of 6 goals, on average, and compute the probability of a goal during each second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e05e31",
      "metadata": {
        "id": "a3e05e31"
      },
      "outputs": [],
      "source": [
        "n = 3600\n",
        "m = 6\n",
        "p = m / 3600\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a221b23a",
      "metadata": {
        "id": "a221b23a"
      },
      "source": [
        "The following function simulates `n` seconds and uses `argmax` to find the time of the first goal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1052b2",
      "metadata": {
        "id": "8c1052b2"
      },
      "outputs": [],
      "source": [
        "def simulate_first_goal(n, p):\n",
        "    return flip(n, p).argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56185216",
      "metadata": {
        "id": "56185216"
      },
      "source": [
        "This works because the result from `flip` is a sequence of 1s and 0s, so the maximum is almost always 1.\n",
        "If there is at least one goal in the sequence, `argmax` returns the index of the first.\n",
        "If there are no goals, it returns 0, but that happens seldom enough that we'll ignore it.\n",
        "\n",
        "We'll use `simulate_first_goal` to simulate 1001 games and make a list of the times until the first goal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92ce08d",
      "metadata": {
        "tags": [],
        "id": "a92ce08d"
      },
      "outputs": [],
      "source": [
        "np.random.seed(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380ff529",
      "metadata": {
        "id": "380ff529"
      },
      "outputs": [],
      "source": [
        "first_goal_times = [simulate_first_goal(n, p) for i in range(1001)]\n",
        "mean = np.mean(first_goal_times)\n",
        "mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0ee4dd3",
      "metadata": {
        "id": "b0ee4dd3"
      },
      "source": [
        "The average time until the first goal is close to 600 seconds, or 10 minutes.\n",
        "And that makes sense -- if we expect 6 goals per sixty-minute game, we expect one goal every 10 minutes, on average.\n",
        "\n",
        "When `n` is large and `p` is small, we can show mathematically that the expected time until the first goal follows an exponential distribution.\n",
        "\n",
        "Because the simulation generates many unique time values, we'll use CDFs to compare distributions, rather than PMFs.\n",
        "And the CDF of the exponential distribution is easy to compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a306c50",
      "metadata": {
        "id": "1a306c50"
      },
      "outputs": [],
      "source": [
        "def exponential_cdf(x, lam):\n",
        "    \"\"\"Compute the exponential CDF.\n",
        "\n",
        "    x: float or sequence of floats\n",
        "    lam: rate parameter\n",
        "\n",
        "    returns: float or NumPy array of cumulative probability\n",
        "    \"\"\"\n",
        "    return 1 - np.exp(-lam * x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fdccc6c",
      "metadata": {
        "id": "4fdccc6c"
      },
      "source": [
        "The value of `lam`, is the average number of events per unit of time -- in this example it is goals per second.\n",
        "We can use the mean of the simulated results to compute `lam`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dfbaf1d",
      "metadata": {
        "id": "2dfbaf1d"
      },
      "outputs": [],
      "source": [
        "lam = 1 / mean\n",
        "lam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e5cfba3",
      "metadata": {
        "id": "5e5cfba3"
      },
      "source": [
        "If we call this function with a range of time values, we can approximate the distribution of first goal times.\n",
        "The NumPy function `linspace` creates an array of equally-spaced values; in this example, it computes 201 values from 0 to 3600, including both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f133ab",
      "metadata": {
        "id": "07f133ab"
      },
      "outputs": [],
      "source": [
        "from empiricaldist import Cdf\n",
        "\n",
        "ts = np.linspace(0, 3600, 201)\n",
        "ps = exponential_cdf(ts, lam)\n",
        "cdf_expo = Cdf(ps, ts, name=\"exponential model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "084f957c",
      "metadata": {
        "id": "084f957c"
      },
      "source": [
        "The following figure compares the simulation results to the exponential distribution we just computed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09108861",
      "metadata": {
        "id": "09108861"
      },
      "outputs": [],
      "source": [
        "cdf_sim = Cdf.from_seq(first_goal_times, name=\"simulation\")\n",
        "\n",
        "cdf_expo.plot(ls=\":\", color=\"gray\")\n",
        "cdf_sim.plot()\n",
        "\n",
        "decorate(xlabel=\"Time of first goal (seconds)\", ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15579092",
      "metadata": {
        "id": "15579092"
      },
      "source": [
        "The exponential model fits the results from the simulation very well -- but a stronger test is to see how it does with real data.\n",
        "\n",
        "The following loop reads the results for all games, gets the time of the first goal, and stores the result in a list.\n",
        "If no goals were scored, it adds `nan` to the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac770972",
      "metadata": {
        "tags": [],
        "id": "ac770972"
      },
      "outputs": [],
      "source": [
        "filename = \"nhl_2023_2024.hdf\"\n",
        "\n",
        "with pd.HDFStore(filename, \"r\") as store:\n",
        "    keys = store.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae894db8",
      "metadata": {
        "id": "ae894db8"
      },
      "outputs": [],
      "source": [
        "firsts = []\n",
        "\n",
        "for key in keys:\n",
        "    times = pd.read_hdf(filename, key=key)\n",
        "    if len(times) > 0:\n",
        "        firsts.append(times[0])\n",
        "    else:\n",
        "        firsts.append(np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc068e1c",
      "metadata": {
        "id": "dc068e1c"
      },
      "source": [
        "To estimate the goal-scoring rate, we can use `nanmean`, which computes the mean of the times, ignoring `nan` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e582dd",
      "metadata": {
        "id": "34e582dd"
      },
      "outputs": [],
      "source": [
        "lam = 1 / np.nanmean(firsts)\n",
        "lam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3424954f",
      "metadata": {
        "id": "3424954f"
      },
      "source": [
        "Now we can compute the CDF of an exponential distribution with the same goal-scoring rate as the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b735052d",
      "metadata": {
        "id": "b735052d"
      },
      "outputs": [],
      "source": [
        "ps = exponential_cdf(ts, lam)\n",
        "cdf_expo = Cdf(ps, ts, name=\"exponential model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fec90844",
      "metadata": {
        "id": "fec90844"
      },
      "source": [
        "To compute the CDF of the data, we'll use the `dropna=False` argument, which includes `nan` values at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8211d5a",
      "metadata": {
        "id": "c8211d5a"
      },
      "outputs": [],
      "source": [
        "cdf_firsts = Cdf.from_seq(firsts, name=\"data\", dropna=False)\n",
        "cdf_firsts.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab13fa7",
      "metadata": {
        "id": "2ab13fa7"
      },
      "source": [
        "The following figure compares the exponential distribution to the distribution of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514f52fe",
      "metadata": {
        "scrolled": true,
        "id": "514f52fe"
      },
      "outputs": [],
      "source": [
        "cdf_expo.plot(ls=\":\", color=\"gray\")\n",
        "cdf_firsts.plot()\n",
        "\n",
        "decorate(xlabel=\"Time of first goal (seconds)\", ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc25e009",
      "metadata": {
        "id": "dc25e009"
      },
      "source": [
        "The data deviate from the model in some places -- it looks like there are fewer goals in the first 1000 seconds than the model predicts.\n",
        "But still, the model fits the data well.\n",
        "\n",
        "The underlying assumption of these models -- the Poisson model of goals and the exponential model of times -- is that a goal is equally likely during any second of a game.\n",
        "If you ask a hockey fan whether that's true, they would say no, and they would be right -- the real world violates assumptions like these in many ways.\n",
        "Nevertheless, theoretical distributions often fit real data remarkably well."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58afaa9f",
      "metadata": {
        "tags": [],
        "id": "58afaa9f"
      },
      "source": [
        "(section_normal)=\n",
        "## The Normal Distribution\n",
        "\n",
        "Many things we measure in the real world follow a **normal distribution**, also known as a Gaussian distribution or a \"bell curve\".\n",
        "To see where these distributions come from, let's consider a model of the way giant pumpkins grow.\n",
        "Suppose that each day, a pumpkin gains 1 pound if the weather is bad, 2 pounds if the weather is fair, and 3 pounds if the weather is good.\n",
        "And suppose the weather each day is bad, fair, or good with the same probability.\n",
        "\n",
        "We can use the following function to simulate this model for `n` days and return the total of the weight gains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbcb8fb",
      "metadata": {
        "id": "3cbcb8fb"
      },
      "outputs": [],
      "source": [
        "def simulate_growth(n):\n",
        "    choices = [1, 2, 3]\n",
        "    gains = np.random.choice(choices, n)\n",
        "    return gains.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90a600a",
      "metadata": {
        "id": "b90a600a"
      },
      "source": [
        "NumPy's `random` module provides a `choice` function that generates an array of `n` random selections from a sequence of values, `choices` in this example.\n",
        "\n",
        "Now suppose 1001 people grow giant pumpkins in different places with different weather.\n",
        "If we simulate the growth process for 100 days, we get a list of 1001 weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f08810",
      "metadata": {
        "id": "d6f08810"
      },
      "outputs": [],
      "source": [
        "sim_weights = [simulate_growth(100) for i in range(1001)]\n",
        "m, s = np.mean(sim_weights), np.std(sim_weights)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0982329",
      "metadata": {
        "id": "f0982329"
      },
      "source": [
        "The mean is close to 200 pounds and the standard deviation is about 8 pounds.\n",
        "To see whether the weights follow a normal distribution, we'll use the following function, which takes a sample and makes a `Cdf` that represents a normal distribution with the same mean and standard deviation as the sample, evaluated over the range from 4 standard deviations below the mean to 4 standard deviations above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d51f4c59",
      "metadata": {
        "id": "d51f4c59"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "def make_normal_model(data):\n",
        "    m, s = np.mean(data), np.std(data)\n",
        "    low, high = m - 4 * s, m + 4 * s\n",
        "    qs = np.linspace(low, high, 201)\n",
        "    ps = norm.cdf(qs, m, s)\n",
        "    return Cdf(ps, qs, name=\"normal model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04258779",
      "metadata": {
        "id": "04258779"
      },
      "source": [
        "Here's how we use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5e0fff",
      "metadata": {
        "id": "ae5e0fff"
      },
      "outputs": [],
      "source": [
        "cdf_model = make_normal_model(sim_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "299e1662",
      "metadata": {
        "id": "299e1662"
      },
      "source": [
        "Now we can make a `Cdf` that represents the distribution of the simulation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bc72cf",
      "metadata": {
        "id": "09bc72cf"
      },
      "outputs": [],
      "source": [
        "cdf_sim_weights = Cdf.from_seq(sim_weights, name=\"simulation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "361ba786",
      "metadata": {
        "id": "361ba786"
      },
      "source": [
        "We'll use the following function to compare the distributions.\n",
        "`cdf_model` and `cdf_data` are `Cdf` objects.\n",
        "`xlabel` is a string, and `options` is a dictionary of options that controls the way `cdf_data` is plotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9257e03",
      "metadata": {
        "id": "a9257e03"
      },
      "outputs": [],
      "source": [
        "def two_cdf_plots(cdf_model, cdf_data, xlabel=\"\", **options):\n",
        "    cdf_model.plot(ls=\":\", color=\"gray\")\n",
        "    cdf_data.plot(**options)\n",
        "    decorate(xlabel=xlabel, ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce39f20b",
      "metadata": {
        "id": "ce39f20b"
      },
      "source": [
        "And here are the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1fc84d",
      "metadata": {
        "id": "4e1fc84d"
      },
      "outputs": [],
      "source": [
        "two_cdf_plots(cdf_model, cdf_sim_weights, xlabel=\"Weight (pounds)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ba6267",
      "metadata": {
        "id": "f1ba6267"
      },
      "source": [
        "The normal model fits the distribution of the weights very well.\n",
        "In general, when we add up enough random factors, the sum tends to follow a normal distribution.\n",
        "That's a consequence of the Central Limit Theorem, which we'll come back to in [Chapter 14](section_central_limit_theorem).\n",
        "\n",
        "But first let's see how well the normal distribution fits real data.\n",
        "As an example, we'll look at the distribution of birth weights in the National Survey of Family Growth (NSFG).\n",
        "We can use `read_fem_preg` to read the data, then select the `totalwgt_lb` column, which records birth weights in pounds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ee353b",
      "metadata": {
        "tags": [],
        "id": "97ee353b"
      },
      "source": [
        "The following cells download the data files and install `statadict`, which we need to read the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5486a05a",
      "metadata": {
        "tags": [],
        "id": "5486a05a"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/nsfg.py\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dct\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dat.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab393c8",
      "metadata": {
        "tags": [],
        "id": "6ab393c8"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import statadict\n",
        "except ImportError:\n",
        "    %pip install statadict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a65ba55",
      "metadata": {
        "id": "8a65ba55"
      },
      "outputs": [],
      "source": [
        "import nsfg\n",
        "\n",
        "preg = nsfg.read_fem_preg()\n",
        "birth_weights = preg[\"totalwgt_lb\"].dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74fe7638",
      "metadata": {
        "id": "74fe7638"
      },
      "source": [
        "The average of the birth weights is about 7.27 pounds, and the standard deviation is 1.4 pounds, but as we've seen, there are some outliers in this dataset that are probably errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fb28ee",
      "metadata": {
        "id": "02fb28ee"
      },
      "outputs": [],
      "source": [
        "m, s = np.mean(birth_weights), np.std(birth_weights)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5216bb4",
      "metadata": {
        "id": "a5216bb4"
      },
      "source": [
        "To reduce the effect of the outliers on the estimated mean and standard deviation, we'll use the SciPy function `trimboth` to remove the highest and lowest values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70b9c45c",
      "metadata": {
        "id": "70b9c45c"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import trimboth\n",
        "\n",
        "trimmed = trimboth(birth_weights, 0.01)\n",
        "m, s = np.mean(trimmed), np.std(trimmed)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd0f6d53",
      "metadata": {
        "id": "bd0f6d53"
      },
      "source": [
        "With the trimmed data, the mean is a little lower and the standard deviation is substantially lower.\n",
        "We'll use the trimmed data to make a normal model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f7462a",
      "metadata": {
        "id": "78f7462a"
      },
      "outputs": [],
      "source": [
        "cdf_model = make_normal_model(trimmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f4e1d8",
      "metadata": {
        "id": "47f4e1d8"
      },
      "source": [
        "And compare it to the `Cdf` of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519a5674",
      "metadata": {
        "id": "519a5674"
      },
      "outputs": [],
      "source": [
        "cdf_birth_weight = Cdf.from_seq(birth_weights, name='data')\n",
        "\n",
        "two_cdf_plots(cdf_model, cdf_birth_weight, xlabel=\"Birth weight (pounds)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58346f03",
      "metadata": {
        "id": "58346f03"
      },
      "source": [
        "The normal model fits the data well except below 5 pounds, where the distribution of the data is to the left of the model -- that is, the lightest babies are lighter than we'd expect in a normal distribution.\n",
        "The real world is usually more complicated than simple mathematical models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0690e053",
      "metadata": {
        "tags": [],
        "id": "0690e053"
      },
      "source": [
        "(section_lognormal_distribution)=\n",
        "## The Lognormal Distribution\n",
        "\n",
        "In the previous section, we simulated pumpkin growth under the assumption that pumpkins grow 1-3 pounds per day, depending on the weather.\n",
        "Instead, let's suppose their growth is proportional to their current weight, so big pumpkins gain more weight per day than small pumpkins -- which is probably more realistic.\n",
        "\n",
        "The following function simulates this kind of proportional growth, where a pumpkin gains 3% of its weight if the weather is bad, 5% if the weather is fair, and 7% if the weather is good.\n",
        "Again, we'll assume that the weather is bad, fair, or good on any given day with equal probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19fc51ca",
      "metadata": {
        "id": "19fc51ca"
      },
      "outputs": [],
      "source": [
        "def simulate_proportionate_growth(n):\n",
        "    choices = [1.03, 1.05, 1.07]\n",
        "    gains = np.random.choice(choices, n)\n",
        "    return gains.prod()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ed4173",
      "metadata": {
        "id": "87ed4173"
      },
      "source": [
        "If a pumpkin gains 3% of its weight, the final weight is the product of the initial weight and the factor 1.03.\n",
        "So we can compute the weight after 100 days by choosing random factors and multiplying them together.\n",
        "\n",
        "We'll call this function 1001 times to simulate 1001 pumpkins and save their weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef49be7",
      "metadata": {
        "id": "fef49be7"
      },
      "outputs": [],
      "source": [
        "sim_weights = [simulate_proportionate_growth(100) for i in range(1001)]\n",
        "np.mean(sim_weights), np.std(sim_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caaf6579",
      "metadata": {
        "id": "caaf6579"
      },
      "source": [
        "The average weight is about 131 pounds; the standard deviation is about 21 pounds.\n",
        "So the pumpkins in this model are smaller but more variable than in the previous model.\n",
        "\n",
        "And we can show mathematically that they follow a **lognormal distribution**, which means that the logarithms of the weights follow a normal distribution.\n",
        "To check, we'll compute the logs of the weights and their mean and standard deviation.\n",
        "We could use logarithms with any base, but I'll use base 10 because it makes the results easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bbd4a9a",
      "metadata": {
        "id": "3bbd4a9a"
      },
      "outputs": [],
      "source": [
        "log_sim_weights = np.log10(sim_weights)\n",
        "m, s = np.mean(log_sim_weights), np.std(log_sim_weights)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2baedea6",
      "metadata": {
        "id": "2baedea6"
      },
      "source": [
        "Now let's compare the distribution of the logarithms to a normal distribution with the same mean and standard deviation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "443e7661",
      "metadata": {
        "id": "443e7661"
      },
      "outputs": [],
      "source": [
        "cdf_model = make_normal_model(log_sim_weights)\n",
        "cdf_log_sim_weights = Cdf.from_seq(log_sim_weights, name=\"simulation\")\n",
        "\n",
        "two_cdf_plots(\n",
        "    cdf_model, cdf_log_sim_weights, xlabel=\"Pumpkin weight (log10 pounds)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0051c07",
      "metadata": {
        "id": "d0051c07"
      },
      "source": [
        "The model fits the simulation result very well, which is what we expected.\n",
        "\n",
        "If people are like pumpkins, where the change in weight from year to year is proportionate to their current weight, we might expect the distribution of adult weights to follow a lognormal distribution.\n",
        "Let's find out.\n",
        "\n",
        "The National Center for Chronic Disease Prevention and Health Promotion conducts an annual survey as part of the Behavioral Risk Factor Surveillance System (BRFSS).\n",
        "In 2008, they interviewed 414,509 respondents and asked about their demographics, health, and health risks.\n",
        "Among the data they collected are the weights of 398,484 respondents.\n",
        "Instructions for downloading the data are in the notebook for this chapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80d103c",
      "metadata": {
        "tags": [],
        "id": "d80d103c"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/CDBRFS08.ASC.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b92b002",
      "metadata": {
        "id": "5b92b002"
      },
      "source": [
        "The `thinkstats` module provides a function that reads BRFSS data and returns a Pandas `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e38e93a",
      "metadata": {
        "id": "0e38e93a"
      },
      "outputs": [],
      "source": [
        "from thinkstats import read_brfss\n",
        "\n",
        "brfss = read_brfss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb5e75b",
      "metadata": {
        "id": "7cb5e75b"
      },
      "source": [
        "Adult weights in kilograms are recorded in the `wtkg2` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea83cdd",
      "metadata": {
        "id": "7ea83cdd"
      },
      "outputs": [],
      "source": [
        "adult_weights = brfss[\"wtkg2\"].dropna()\n",
        "m, s = np.mean(adult_weights), np.std(adult_weights)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf89666",
      "metadata": {
        "id": "0bf89666"
      },
      "source": [
        "The mean is about 79 kg.\n",
        "Before we compute logarithms, let's see if the weights follow a normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc748844",
      "metadata": {
        "id": "fc748844"
      },
      "outputs": [],
      "source": [
        "cdf_model = make_normal_model(adult_weights)\n",
        "cdf_adult_weights = Cdf.from_seq(adult_weights, name=\"adult weight\")\n",
        "\n",
        "two_cdf_plots(cdf_model, cdf_adult_weights, xlabel=\"Adult weight (kilograms)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bccb11f",
      "metadata": {
        "id": "8bccb11f"
      },
      "source": [
        "The normal distribution might be a good enough model for this data, for some purposes -- but let's see if we can do better.\n",
        "\n",
        "Here's the distribution of the log-transformed weights and a normal model with the same mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b2f37f",
      "metadata": {
        "id": "77b2f37f"
      },
      "outputs": [],
      "source": [
        "log_adult_weights = np.log10(adult_weights)\n",
        "cdf_model = make_normal_model(log_adult_weights)\n",
        "\n",
        "cdf_log_adult_weights = Cdf.from_seq(log_adult_weights, name=\"log adult weight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4d7124",
      "metadata": {
        "scrolled": true,
        "id": "6d4d7124"
      },
      "outputs": [],
      "source": [
        "two_cdf_plots(cdf_model, cdf_log_adult_weights, xlabel=\"Adult weight (log10 kg)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76dcae0d",
      "metadata": {
        "id": "76dcae0d"
      },
      "source": [
        "The normal model fits the logarithms better than it fits the weights themselves, which suggests that proportional growth is a better model of weight gain than additive growth."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f46ee83",
      "metadata": {
        "id": "0f46ee83"
      },
      "source": [
        "## Why model?\n",
        "\n",
        "At the beginning of this chapter, I said that many real world phenomena can be modeled with theoretical distributions.\n",
        "But it might not have been clear why we should care.\n",
        "\n",
        "Like all models, theoretical distributions are abstractions, which means they leave out details that are considered irrelevant.\n",
        "For example, an observed distribution might have measurement errors or quirks that are specific to the sample; theoretical models ignore these idiosyncrasies.\n",
        "\n",
        "Theoretical models are also a form of data compression.\n",
        "When a model fits a dataset well, a small set of numbers can summarize a large amount of data.\n",
        "\n",
        "It is sometimes surprising when data from a natural phenomenon fit a theoretical distribution, but these observations can provide insight into physical systems.\n",
        "Sometimes we can explain why an observed distribution has a particular form.\n",
        "For example, in the previous section we found that adult weights are well-modeled by a lognormal distribution, which suggests that changes in weight from year to year might be proportional to current weight."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "439331ea",
      "metadata": {
        "id": "439331ea"
      },
      "source": [
        "Also, theoretical distributions lend themselves to mathematical analysis, as we'll see in [Chapter 14](chapter_analytic_methods).\n",
        "\n",
        "But it is important to remember that all models are imperfect.\n",
        "Data from the real world never fit a theoretical distribution perfectly.\n",
        "People sometimes talk as if data are generated by models; for example, they might say that the distribution of human heights is normal, or the distribution of income is lognormal.\n",
        "Taken literally, these claims cannot be true -- there are always differences between the real world and mathematical models.\n",
        "\n",
        "Models are useful if they capture the relevant aspects of the real world and leave out unneeded details.\n",
        "But what is relevant or unneeded depends on what you are planning to use the model for."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c55372d",
      "metadata": {
        "id": "9c55372d"
      },
      "source": [
        "## Glossary\n",
        "\n",
        "- **binomial distribution:** A theoretical distribution often used to model the number of successes or hits in a sequence of hits and misses.\n",
        "\n",
        "- **Poisson distribution:** A theoretical distribution often used to model the number of events that occur in an interval of time.\n",
        "\n",
        "- **exponential distribution:** A theoretical distribution often used to model the time between events.\n",
        "\n",
        "- **normal distribution:** A theoretical distribution often used to model data that follow a symmetric, bell-like curve.\n",
        "\n",
        "- **lognormal distribution:** A theoretical distribution often used to model data that follow a bell-like curve that is skewed to the right."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f3aa6e",
      "metadata": {
        "collapsed": true,
        "id": "70f3aa6e"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4608be3e",
      "metadata": {
        "id": "4608be3e"
      },
      "source": [
        "### Exercise 5.1\n",
        "\n",
        "In the NSFG respondent file, the `numfmhh` column records the \"number of family members in\" each respondent's household.\n",
        "We can use `read_fem_resp` to read the file, and `query` to select respondents who were 25 or older when they were interviewed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb919b34",
      "metadata": {
        "tags": [],
        "id": "eb919b34"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemResp.dct\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemResp.dat.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032f7704",
      "metadata": {
        "id": "032f7704"
      },
      "outputs": [],
      "source": [
        "from nsfg import read_fem_resp\n",
        "\n",
        "resp = read_fem_resp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32777c1c",
      "metadata": {
        "id": "32777c1c"
      },
      "outputs": [],
      "source": [
        "older = resp.query(\"age >= 25\")\n",
        "num_family = older[\"numfmhh\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "249de556",
      "metadata": {
        "id": "249de556"
      },
      "source": [
        "Compute the `Pmf` of `numfmhh` for these older respondents and compare it with a Poisson distribution with the same mean.\n",
        "How well does the Poisson model fit the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aab6cfb",
      "metadata": {
        "id": "8aab6cfb"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390873eb",
      "metadata": {
        "id": "390873eb"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6206d2d6",
      "metadata": {
        "id": "6206d2d6"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "165d7fea",
      "metadata": {
        "id": "165d7fea"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e49d067a",
      "metadata": {
        "id": "e49d067a"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5b94ad",
      "metadata": {
        "id": "6d5b94ad"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d2bf28f",
      "metadata": {
        "id": "2d2bf28f"
      },
      "source": [
        "### Exercise 5.2\n",
        "\n",
        "Earlier in this chapter we saw that the time until the first goal in a hockey game follows an exponential distribution.\n",
        "If our model of goal-scoring is correct, a goal is equally likely at any time, regardless of how long it has been since the previous goal.\n",
        "And if that's true, we expect the time between goals to follow an exponential distribution, too.\n",
        "\n",
        "The following loop reads the hockey data again, computes the time between successive goals, if there is more than one in a game, and collects the inter-goal times in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e775e0",
      "metadata": {
        "tags": [],
        "id": "65e775e0"
      },
      "outputs": [],
      "source": [
        "filename = \"nhl_2023_2024.hdf\"\n",
        "\n",
        "with pd.HDFStore(filename, \"r\") as store:\n",
        "    keys = store.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02f9d7c",
      "metadata": {
        "id": "c02f9d7c"
      },
      "outputs": [],
      "source": [
        "intervals = []\n",
        "\n",
        "for key in keys:\n",
        "    times = pd.read_hdf(filename, key=key)\n",
        "    if len(times) > 1:\n",
        "        intervals.extend(times.diff().dropna())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8848768b",
      "metadata": {
        "id": "8848768b"
      },
      "source": [
        "Use `exponential_cdf` to compute the CDF of an exponential distribution with the same mean as the observed intervals and compare this model to the CDF of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad78619",
      "metadata": {
        "id": "5ad78619"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e46bc6",
      "metadata": {
        "id": "93e46bc6"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26696a2f",
      "metadata": {
        "id": "26696a2f"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77cb2f0",
      "metadata": {
        "scrolled": true,
        "id": "e77cb2f0"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c04ac0",
      "metadata": {
        "id": "e3c04ac0"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82106650",
      "metadata": {
        "id": "82106650"
      },
      "source": [
        "### Exercise 5.3\n",
        "\n",
        "Is the distribution of human height more like a normal or a lognormal distribution?\n",
        "To find out, we can select height data from the BRFSS like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1916f8dc",
      "metadata": {
        "id": "1916f8dc"
      },
      "outputs": [],
      "source": [
        "adult_heights = brfss[\"htm3\"].dropna()\n",
        "m, s = np.mean(adult_heights), np.std(adult_heights)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f894fdf1",
      "metadata": {
        "id": "f894fdf1"
      },
      "source": [
        "Compute the CDF of these values and compare it to a normal distribution with the same mean and standard deviation.\n",
        "Then compute the logarithms of the heights and compute the distribution of the logarithms to a normal distribution.\n",
        "Based on a visual comparison, which model fits the data better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5c0630",
      "metadata": {
        "id": "4b5c0630"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2435a8f8",
      "metadata": {
        "id": "2435a8f8"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387cf404",
      "metadata": {
        "id": "387cf404"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c337cb43",
      "metadata": {
        "id": "c337cb43"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724121e7",
      "metadata": {
        "id": "724121e7"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d2d938",
      "metadata": {
        "id": "42d2d938"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27da3a4",
      "metadata": {
        "tags": [],
        "id": "e27da3a4"
      },
      "source": [
        "[Think Stats: Exploratory Data Analysis in Python, 3rd Edition](https://allendowney.github.io/ThinkStats/index.html)\n",
        "\n",
        "Copyright 2024 [Allen B. Downey](https://allendowney.com)\n",
        "\n",
        "Code license: [MIT License](https://mit-license.org/)\n",
        "\n",
        "Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}