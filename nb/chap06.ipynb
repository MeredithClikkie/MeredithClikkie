{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeredithClikkie/MeredithClikkie/blob/main/nb/chap06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418e407e",
      "metadata": {
        "id": "418e407e"
      },
      "source": [
        "The third edition of *Think Stats* is available now from [Bookshop.org](https://bookshop.org/a/98697/9781098190255) and [Amazon](https://amzn.to/42lmxwu) (those are affiliate links). If you are enjoying the free, online version, consider [buying me a coffee](https://buymeacoffee.com/allendowney)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a7c13a",
      "metadata": {
        "id": "83a7c13a"
      },
      "source": [
        "# Probability Density Functions\n",
        "\n",
        "In the previous chapter, we modeled data with theoretical distributions including the binomial, Poisson, exponential, and normal distributions.\n",
        "\n",
        "The binomial and Poisson distributions are **discrete**, which means that the outcomes have to be distinct or separate elements, like an integer number of hits and misses, or goals scored.\n",
        "In a discrete distribution, each outcome is associated with a probability mass.\n",
        "\n",
        "The exponential and normal distribution are **continuous**, which means the outcomes can be at any point in a range of possible values.\n",
        "In a continuous distribution, each outcome is associated with a **probability density**.\n",
        "Probability density is an abstract idea, and many people find it difficult at first, but we'll take it one step at a time.\n",
        "As a first step, let's think again about comparing distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c77a2e",
      "metadata": {
        "tags": [],
        "id": "b2c77a2e"
      },
      "source": [
        "[Click here to run this notebook on Colab](https://colab.research.google.com/github/AllenDowney/ThinkStats/blob/v3/nb/chap06.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "79f64f53",
      "metadata": {
        "tags": [],
        "id": "79f64f53",
        "outputId": "1a548545-c436-45e6-ae7c-5cedcadb60ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded thinkstats.py\n"
          ]
        }
      ],
      "source": [
        "from os.path import basename, exists\n",
        "\n",
        "\n",
        "def download(url):\n",
        "    filename = basename(url)\n",
        "    if not exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print(\"Downloaded \" + local)\n",
        "\n",
        "\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3d4912",
      "metadata": {
        "tags": [],
        "id": "3b3d4912",
        "outputId": "36294301-cf9b-491a-e5d4-02a943e9f98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting empiricaldist\n",
            "  Downloading empiricaldist-0.9.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from empiricaldist) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from empiricaldist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from empiricaldist) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from empiricaldist) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->empiricaldist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->empiricaldist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->empiricaldist) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->empiricaldist) (1.17.0)\n",
            "Building wheels for collected packages: empiricaldist\n",
            "  Building wheel for empiricaldist (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empiricaldist: filename=empiricaldist-0.9.0-py3-none-any.whl size=14296 sha256=a7a9d5f094a68342955b05187814f8105653c19b25822ae5c73dbdc497fc7fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/56/da/ea90b6b66dc5e72379a64e2819815066873f00c1350126e876\n",
            "Successfully built empiricaldist\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import empiricaldist\n",
        "except ImportError:\n",
        "    %pip install empiricaldist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955f8f40",
      "metadata": {
        "tags": [],
        "id": "955f8f40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from thinkstats import decorate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f90e9d5",
      "metadata": {
        "id": "6f90e9d5"
      },
      "source": [
        "## Comparing Distributions\n",
        "\n",
        "In the previous chapter, when we compared discrete distributions, we used a bar plot to show their probability mass functions (PMFs).\n",
        "When we compared continuous distributions, we used a line plot to show their cumulative distribution functions (CDFs).\n",
        "\n",
        "For the discrete distributions, we could also have used CDFs.\n",
        "For example, here's the PMF of a Poisson distribution with `lam=2.2`, which is a good model for the distribution of household size in the NSFG data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b74d4646",
      "metadata": {
        "tags": [],
        "id": "b74d4646"
      },
      "source": [
        "The following cells download the data files and install `statadict`, which we need to read the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c3271b",
      "metadata": {
        "tags": [],
        "id": "54c3271b"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/nsfg.py\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemResp.dct\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemResp.dat.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "366f036d",
      "metadata": {
        "tags": [],
        "id": "366f036d"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import statadict\n",
        "except ImportError:\n",
        "    %pip install statadict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d668f128",
      "metadata": {
        "id": "d668f128"
      },
      "source": [
        "We can use `read_fem_resp` to read the respondent data file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c181f9",
      "metadata": {
        "id": "06c181f9"
      },
      "outputs": [],
      "source": [
        "from nsfg import read_fem_resp\n",
        "\n",
        "resp = read_fem_resp()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3124a1df",
      "metadata": {
        "id": "3124a1df"
      },
      "source": [
        "Next we'll select household sizes for people 25 and older."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605099ec",
      "metadata": {
        "id": "605099ec"
      },
      "outputs": [],
      "source": [
        "older = resp.query(\"age >= 25\")\n",
        "num_family = older[\"numfmhh\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1c1d7e",
      "metadata": {
        "id": "1f1c1d7e"
      },
      "source": [
        "And make a `Pmf` that represents the distribution of responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763da396",
      "metadata": {
        "id": "763da396"
      },
      "outputs": [],
      "source": [
        "from empiricaldist import Pmf\n",
        "\n",
        "pmf_family = Pmf.from_seq(num_family, name=\"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9e8c8ad",
      "metadata": {
        "id": "d9e8c8ad"
      },
      "source": [
        "Here's another `Pmf` that represents a Poisson distribution with the same mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a4d6062",
      "metadata": {
        "id": "4a4d6062"
      },
      "outputs": [],
      "source": [
        "from thinkstats import poisson_pmf\n",
        "\n",
        "lam = 2.2\n",
        "ks = np.arange(11)\n",
        "ps = poisson_pmf(ks, lam)\n",
        "\n",
        "pmf_poisson = Pmf(ps, ks, name=\"Poisson model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4639ed8",
      "metadata": {
        "id": "f4639ed8"
      },
      "source": [
        "And here's how the distribution of the data compares to the Poisson model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70ae409",
      "metadata": {
        "id": "f70ae409"
      },
      "outputs": [],
      "source": [
        "from thinkstats import two_bar_plots\n",
        "\n",
        "two_bar_plots(pmf_family, pmf_poisson)\n",
        "decorate(xlabel=\"Number of family members\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc92687",
      "metadata": {
        "id": "6bc92687"
      },
      "source": [
        "Comparing the PMFs, we can see that the model fits the data well, but with some deviations.\n",
        "\n",
        "To get a sense of how substantial those deviations are, it can be helpful to compare CDFs.\n",
        "We can use `make_cdf` to compute the CDFs of the data and the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e8e079",
      "metadata": {
        "id": "54e8e079"
      },
      "outputs": [],
      "source": [
        "cdf_family = pmf_family.make_cdf()\n",
        "cdf_poisson = pmf_poisson.make_cdf()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb7ecb4",
      "metadata": {
        "id": "2fb7ecb4"
      },
      "source": [
        "Here's what they look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001fc097",
      "metadata": {
        "id": "001fc097"
      },
      "outputs": [],
      "source": [
        "from thinkstats import two_cdf_plots\n",
        "\n",
        "two_cdf_plots(cdf_poisson, cdf_family)\n",
        "decorate(xlabel=\"Number of family members\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef2b2a89",
      "metadata": {
        "id": "ef2b2a89"
      },
      "source": [
        "When we compare CDFs, the deviations are less prominent, but we can see where and how the distributions differ.\n",
        "PMFs tend to emphasize small differences -- sometimes CDFs provide a better sense of the big picture.\n",
        "\n",
        "CDFs also work well with continuous data. As an example, let's look at the distribution of birth weights again, which is in the NSFG pregnancy file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbe6cab",
      "metadata": {
        "tags": [],
        "id": "fcbe6cab"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dct\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dat.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d674fef",
      "metadata": {
        "id": "0d674fef"
      },
      "outputs": [],
      "source": [
        "from nsfg import read_fem_preg\n",
        "\n",
        "preg = read_fem_preg()\n",
        "birth_weights = preg[\"totalwgt_lb\"].dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f125fee8",
      "metadata": {
        "id": "f125fee8"
      },
      "source": [
        "Here is the code we used in the previous chapter to fit a normal model to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a0bd573",
      "metadata": {
        "id": "1a0bd573"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import trimboth\n",
        "from thinkstats import make_normal_model\n",
        "\n",
        "trimmed = trimboth(birth_weights, 0.01)\n",
        "cdf_model = make_normal_model(trimmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16ecb36a",
      "metadata": {
        "id": "16ecb36a"
      },
      "source": [
        "And here's the distribution of the data compared to the normal model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89dc754a",
      "metadata": {
        "id": "89dc754a"
      },
      "outputs": [],
      "source": [
        "from empiricaldist import Cdf\n",
        "\n",
        "cdf_birth_weight = Cdf.from_seq(birth_weights, name=\"sample\")\n",
        "two_cdf_plots(cdf_model, cdf_birth_weight, xlabel=\"Birth weight (pounds)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1757253",
      "metadata": {
        "id": "a1757253"
      },
      "source": [
        "As we saw in the previous chapter, the normal model fits the data well except in the range of the lightest babies.\n",
        "\n",
        "In my opinion, CDFs are usually the best way to compare data to a model.\n",
        "But for audiences that are not familiar with CDFs, there is one more option: probability density functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47cc69d",
      "metadata": {
        "id": "b47cc69d"
      },
      "source": [
        "## Probability Density\n",
        "\n",
        "We'll start with the **probability density function (PDF)** of the normal distribution, which computes the density for the quantities, `xs`, given `mu` and `sigma`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a75926",
      "metadata": {
        "id": "73a75926"
      },
      "outputs": [],
      "source": [
        "def normal_pdf(xs, mu, sigma):\n",
        "    \"\"\"Evaluates the normal probability density function.\"\"\"\n",
        "    z = (xs - mu) / sigma\n",
        "    return np.exp(-(z**2) / 2) / sigma / np.sqrt(2 * np.pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b78cee48",
      "metadata": {
        "id": "b78cee48"
      },
      "source": [
        "For `mu` and `sigma` we'll use the mean and standard deviation of the trimmed birth weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c2db0c",
      "metadata": {
        "id": "65c2db0c"
      },
      "outputs": [],
      "source": [
        "m, s = np.mean(trimmed), np.std(trimmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d75407e",
      "metadata": {
        "id": "8d75407e"
      },
      "source": [
        "Now we'll evaluate `normal_pdf` for a range of weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb6935c",
      "metadata": {
        "id": "cfb6935c"
      },
      "outputs": [],
      "source": [
        "low = m - 4 * s\n",
        "high = m + 4 * s\n",
        "qs = np.linspace(low, high, 201)\n",
        "ps = normal_pdf(qs, m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc1c3d7",
      "metadata": {
        "id": "6cc1c3d7"
      },
      "source": [
        "And plot it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8080871",
      "metadata": {
        "id": "c8080871"
      },
      "outputs": [],
      "source": [
        "plt.plot(qs, ps, label=\"normal model\", ls=\":\", color=\"gray\")\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"Density\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910864d9",
      "metadata": {
        "id": "910864d9"
      },
      "source": [
        "The result looks like a bell curve, which is characteristic of the normal distribution.\n",
        "\n",
        "When we evaluate `normal_pdf`, the result is a probability density.\n",
        "For example, here's the density function evaluated at the mean, which is where the density is highest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecee46bb",
      "metadata": {
        "id": "ecee46bb"
      },
      "outputs": [],
      "source": [
        "normal_pdf(m, m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89451488",
      "metadata": {
        "id": "89451488"
      },
      "source": [
        "By itself, a probability density doesn't mean much -- most importantly, it is *not* a probability.\n",
        "It would be incorrect to say that the probability is 32% that a randomly-chosen birth weight equals `m`.\n",
        "In fact, the probability that a birth weight is truly, exactly, and precisely equal to `m` -- or any other specific value -- is zero.\n",
        "\n",
        "However, we can use the probability densities to compute the probability that an outcome falls in an interval between two values, by computing the area under the curve.\n",
        "\n",
        "We could do that with the `normal_pdf` function, but it is more convenient to use the `NormalPdf` class, which is defined in the `thinkstats` module.\n",
        "Here's how we create a `NormalPdf` object with the same mean and standard deviation as the birth weights in the NSFG dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67c7406",
      "metadata": {
        "id": "d67c7406"
      },
      "outputs": [],
      "source": [
        "from thinkstats import NormalPdf\n",
        "\n",
        "pdf_model = NormalPdf(m, s, name=\"normal model\")\n",
        "pdf_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11cb9399",
      "metadata": {
        "id": "11cb9399"
      },
      "source": [
        "If we call this object like a function, it evaluates the normal PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ee0737",
      "metadata": {
        "id": "40ee0737"
      },
      "outputs": [],
      "source": [
        "pdf_model(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f400a25",
      "metadata": {
        "id": "7f400a25"
      },
      "source": [
        "Now, to compute the area under the PDF, we can use the following function, which takes a `NormalPdf` object and the bounds of an interval, `low` and `high`.\n",
        "It evaluates the normal PDF at equally-spaced quantities between `low` and `high`, and uses the SciPy function `simpson` to estimate the area under the curve (`simpson` is so named because it uses an algorithm called Simpson's method)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2186dbe1",
      "metadata": {
        "id": "2186dbe1"
      },
      "outputs": [],
      "source": [
        "from scipy.integrate import simpson\n",
        "\n",
        "\n",
        "def area_under(pdf, low, high):\n",
        "    qs = np.linspace(low, high, 501)\n",
        "    ps = pdf(qs)\n",
        "    return simpson(y=ps, x=qs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3890ad65",
      "metadata": {
        "id": "3890ad65"
      },
      "source": [
        "If we compute the area under the curve from the lowest to the highest point in the graph, the result is close to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631bade0",
      "metadata": {
        "id": "631bade0"
      },
      "outputs": [],
      "source": [
        "area_under(pdf_model, 2, 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c0dc81",
      "metadata": {
        "id": "87c0dc81"
      },
      "source": [
        "If we extend the interval from negative infinity to positive infinity, the total area is exactly 1.\n",
        "\n",
        "If we start from 0 -- or any value far below the mean -- we can compute the fraction of birth weights less than or equal to 8.5 pounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc85a2dd",
      "metadata": {
        "id": "dc85a2dd"
      },
      "outputs": [],
      "source": [
        "area_under(pdf_model, 0, 8.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ccedba",
      "metadata": {
        "id": "a3ccedba"
      },
      "source": [
        "You might recall that the \"fraction less than or equal to a given value\" is the definition of the CDF.\n",
        "So we could compute the same result using the CDF of the normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45841eca",
      "metadata": {
        "id": "45841eca"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "norm.cdf(8.5, m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27850ccf",
      "metadata": {
        "id": "27850ccf"
      },
      "source": [
        "Similarly, we can use the area under the density curve to compute the fraction of birth weights between 6 and 8 pounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53737676",
      "metadata": {
        "id": "53737676"
      },
      "outputs": [],
      "source": [
        "area_under(pdf_model, 6, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3402340",
      "metadata": {
        "id": "d3402340"
      },
      "source": [
        "Or we can get the same result using the CDF to compute the fraction less than 8 and then subtracting off the fraction less than 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143933f5",
      "metadata": {
        "id": "143933f5"
      },
      "outputs": [],
      "source": [
        "norm.cdf(8, m, s) - norm.cdf(6, m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da31401d",
      "metadata": {
        "id": "da31401d"
      },
      "source": [
        "So the CDF is the area under the curve of the PDF.\n",
        "If you know calculus, another way to say the same thing is that the CDF is the integral of the PDF.\n",
        "And conversely, the PDF is the derivative of the CDF."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b83653",
      "metadata": {
        "tags": [],
        "id": "98b83653"
      },
      "source": [
        "(section_exponential_pdf)=\n",
        "## The Exponential PDF\n",
        "\n",
        "To get your head around probability density, it might help to see another example.\n",
        "In the previous chapter, we used an exponential distribution to model the time until the first goal in a hockey game.\n",
        "We used the following function to compute the exponential CDF, where `lam` is the rate in goals per unit of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fb5032",
      "metadata": {
        "id": "18fb5032"
      },
      "outputs": [],
      "source": [
        "def exponential_cdf(x, lam):\n",
        "    \"\"\"Compute the exponential CDF.\n",
        "\n",
        "    x: float or sequence of floats\n",
        "    lam: rate parameter\n",
        "\n",
        "    returns: float or NumPy array of cumulative probability\n",
        "    \"\"\"\n",
        "    return 1 - np.exp(-lam * x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cbcc93a",
      "metadata": {
        "id": "2cbcc93a"
      },
      "source": [
        "We can compute the PDF of the exponential distribution like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37368771",
      "metadata": {
        "id": "37368771"
      },
      "outputs": [],
      "source": [
        "def exponential_pdf(x, lam):\n",
        "    \"\"\"Evaluates the exponential PDF.\n",
        "\n",
        "    x: float or sequence of floats\n",
        "    lam: rate parameter\n",
        "\n",
        "    returns: float or NumPy array of probability density\n",
        "    \"\"\"\n",
        "    return lam * np.exp(-lam * x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4891494d",
      "metadata": {
        "id": "4891494d"
      },
      "source": [
        "`thinkstats` provides an `ExponentialPdf` object that uses this function to compute the exponential PDF.\n",
        "We can use one to represent an exponential distribution with rate 6 goals per game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f77d24b",
      "metadata": {
        "id": "5f77d24b"
      },
      "outputs": [],
      "source": [
        "from thinkstats import ExponentialPdf\n",
        "\n",
        "lam = 6\n",
        "pdf_expo = ExponentialPdf(lam, name=\"exponential model\")\n",
        "pdf_expo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7095c57f",
      "metadata": {
        "id": "7095c57f"
      },
      "source": [
        "`ExponentialPdf` provides a `plot` function we can use to plot the PDF -- notice that the unit of time is games here, rather than seconds as in the previous chapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d999a2f",
      "metadata": {
        "id": "6d999a2f"
      },
      "outputs": [],
      "source": [
        "qs = np.linspace(0, 1.5, 201)\n",
        "pdf_expo.plot(qs, ls=\":\", color=\"gray\")\n",
        "decorate(xlabel=\"Time (games)\", ylabel=\"Density\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a89be81f",
      "metadata": {
        "id": "a89be81f"
      },
      "source": [
        "Looking at the y-axis, you might notice that some of these densities are greater than 1, which is a reminder that a probability density is not a probability.\n",
        "But the area under a density curve is a probability, so it should never be greater than 1.\n",
        "\n",
        "If we compute the area under this curve from 0 to 1.5 games, we can confirm that the result is close to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0dfefb4",
      "metadata": {
        "id": "c0dfefb4"
      },
      "outputs": [],
      "source": [
        "area_under(pdf_expo, 0, 1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb0e98cd",
      "metadata": {
        "id": "fb0e98cd"
      },
      "source": [
        "If we extend the interval much farther, the result is slightly greater than 1, but that's because we're approximating the area numerically.\n",
        "Mathematically, it is exactly 1, as we can confirm using the exponential CDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57963394",
      "metadata": {
        "id": "57963394"
      },
      "outputs": [],
      "source": [
        "from thinkstats import exponential_cdf\n",
        "\n",
        "exponential_cdf(7, lam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eec9cff",
      "metadata": {
        "id": "6eec9cff"
      },
      "source": [
        "We can use the area under the density curve to compute the probability of a goal during any interval.\n",
        "For example, here is the probability of a goal during the first minute of a 60-minute game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "418d568c",
      "metadata": {
        "id": "418d568c"
      },
      "outputs": [],
      "source": [
        "area_under(pdf_expo, 0, 1 / 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "650d6f29",
      "metadata": {
        "id": "650d6f29"
      },
      "source": [
        "We can compute the same result using the exponential CDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a4f81b",
      "metadata": {
        "id": "f6a4f81b"
      },
      "outputs": [],
      "source": [
        "exponential_cdf(1 / 60, lam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5afe4fb",
      "metadata": {
        "id": "b5afe4fb"
      },
      "source": [
        "In summary, if we evaluate a PDF, the result is a probability density -- which is not a probability.\n",
        "However, if we compute the area under the PDF, the result is the probability that a quantity falls in an interval.\n",
        "Or we can find the same probability by evaluating the CDF at the beginning and end of the interval and computing the difference."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7687b0f",
      "metadata": {
        "id": "f7687b0f"
      },
      "source": [
        "## Comparing PMFs and PDFs\n",
        "\n",
        "It is a common error to compare the PMF of a sample with the PDF of a theoretical model.\n",
        "For example, suppose we want to compare the distribution of birth weights to a normal model.\n",
        "Here's a `Pmf` that represents the distribution of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284649e4",
      "metadata": {
        "id": "284649e4"
      },
      "outputs": [],
      "source": [
        "pmf_birth_weight = Pmf.from_seq(birth_weights, name=\"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d898d5f",
      "metadata": {
        "id": "2d898d5f"
      },
      "source": [
        "And we already have `pdf_model`, which represents the PDF of the normal distribution with the same mean and standard deviation.\n",
        "Here's what happens if we plot them on the same axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f3831b",
      "metadata": {
        "id": "55f3831b"
      },
      "outputs": [],
      "source": [
        "pdf_model.plot(ls=\":\", color=\"gray\")\n",
        "pmf_birth_weight.plot()\n",
        "\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"PMF? Density?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27604636",
      "metadata": {
        "id": "27604636"
      },
      "source": [
        "It doesn't work very well.\n",
        "One reason is that they are not in the same units.\n",
        "A PMF contains probability masses and a PDF contains probability densities, so we can't compare them, and we shouldn't plot them on the same axes.\n",
        "\n",
        "As a first attempt to solve the problem, we can make a `Pmf` that approximates the normal distribution by evaluating the PDF at a discrete set of points.\n",
        "`NormalPdf` provides a `make_pmf` method that does that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f829f686",
      "metadata": {
        "id": "f829f686"
      },
      "outputs": [],
      "source": [
        "pmf_model = pdf_model.make_pmf()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e4d5e7",
      "metadata": {
        "id": "e0e4d5e7"
      },
      "source": [
        "The result is a normalized `Pmf` that contains probability masses, so we can at least plot it on the same axes as the PMF of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36507db8",
      "metadata": {
        "id": "36507db8"
      },
      "outputs": [],
      "source": [
        "pmf_model.plot(ls=\":\", color=\"gray\")\n",
        "pmf_birth_weight.plot()\n",
        "\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8aac9e9",
      "metadata": {
        "id": "b8aac9e9"
      },
      "source": [
        "But this is still not a good way to compare distributions.\n",
        "One problem is that the two `Pmf` objects contain different numbers of quantities, and the quantities in `pmf_birth_weight` are not equally spaced, so the probability masses are not really comparable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a44c0e",
      "metadata": {
        "id": "e6a44c0e"
      },
      "outputs": [],
      "source": [
        "len(pmf_model), len(pmf_birth_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf1cf84",
      "metadata": {
        "id": "5cf1cf84"
      },
      "source": [
        "The other problem is that the `Pmf` of the data is noisy.\n",
        "So let's try something else."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7a5b57",
      "metadata": {
        "tags": [],
        "id": "7d7a5b57"
      },
      "source": [
        "(section_kernel_density_estimation)=\n",
        "## Kernel Density Estimation\n",
        "\n",
        "Instead of using the model to make a PMF, we can use the data to make a PDF.\n",
        "To show how that works, I'll start with a small sample of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d0fb6f",
      "metadata": {
        "tags": [],
        "id": "e6d0fb6f"
      },
      "outputs": [],
      "source": [
        "# Set the random seed so we get the same results every time\n",
        "np.random.seed(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c83c956",
      "metadata": {
        "id": "6c83c956"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "sample = birth_weights.sample(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5356cf",
      "metadata": {
        "id": "8f5356cf"
      },
      "source": [
        "The `Pmf` of this sample looks like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44b1ecd",
      "metadata": {
        "id": "e44b1ecd"
      },
      "outputs": [],
      "source": [
        "for weight in sample:\n",
        "    pmf = Pmf.from_seq([weight]) / n\n",
        "    pmf.bar(width=0.08, alpha=0.5)\n",
        "\n",
        "xlim = [1.5, 12.5]\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"PMF\", xlim=xlim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d7c7e0",
      "metadata": {
        "id": "70d7c7e0"
      },
      "source": [
        "This way of representing the distribution treats the data as if it is discrete, so each probability mass is stacked up on a single point.\n",
        "But birth weight is actually continuous, so the quantities between the measurements are also possible.\n",
        "We can represent that possibility by replacing each discrete probability mass with a continuous probability density, like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd8fe67",
      "metadata": {
        "id": "2bd8fe67"
      },
      "outputs": [],
      "source": [
        "qs = np.linspace(2, 12, 201)\n",
        "\n",
        "for weight in sample:\n",
        "    ps = NormalPdf(weight, 0.75)(qs) / n\n",
        "    plt.plot(qs, ps, alpha=0.5)\n",
        "\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"PDF\", xlim=xlim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0aeeb4",
      "metadata": {
        "id": "bf0aeeb4"
      },
      "source": [
        "For each weight in the sample, we create a `NormalPdf` with the observed weight as the mean -- now let's add them up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065680cb",
      "metadata": {
        "id": "065680cb"
      },
      "outputs": [],
      "source": [
        "low_ps = np.zeros_like(qs)\n",
        "\n",
        "for weight in sample:\n",
        "    ps = NormalPdf(weight, 0.75)(qs) / n\n",
        "    high_ps = low_ps + ps\n",
        "    plt.fill_between(qs, low_ps, high_ps, alpha=0.5, lw=1, ec=\"white\")\n",
        "    low_ps = high_ps\n",
        "\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"PDF\", xlim=xlim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "594b5d14",
      "metadata": {
        "id": "594b5d14"
      },
      "source": [
        "When we add up the probability densities for each data point, the result is an estimate of the probability density for the whole sample.\n",
        "This process is called **kernel density estimation** or KDE.\n",
        "In this context, a \"kernel\" is one of the small density functions we added up.\n",
        "Because the kernels we used are normal distributions -- also known as Gaussians -- we could say more specifically that we computed a Gaussian KDE.\n",
        "\n",
        "SciPy provides a function called `gaussian_kde` that implements this algorithm.\n",
        "Here's how we can use it to estimate the distribution of birth weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3dba7b9",
      "metadata": {
        "id": "c3dba7b9"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "kde = gaussian_kde(birth_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaaa1528",
      "metadata": {
        "id": "eaaa1528"
      },
      "source": [
        "The result is an object that represents the estimated PDF, which we can evaluate by calling it like  a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10685681",
      "metadata": {
        "id": "10685681"
      },
      "outputs": [],
      "source": [
        "ps = kde(qs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be22fbe4",
      "metadata": {
        "id": "be22fbe4"
      },
      "source": [
        "Here's what the result looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a6b73f",
      "metadata": {
        "id": "b5a6b73f"
      },
      "outputs": [],
      "source": [
        "plt.plot(qs, ps)\n",
        "\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"Density\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3283fa",
      "metadata": {
        "id": "1a3283fa"
      },
      "source": [
        "`thinkstats` provides a `Pdf` object that takes the result from `gaussian_kde`, and a domain that indicates where the density should be evaluated.\n",
        "Here's how we make one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0774e65",
      "metadata": {
        "id": "b0774e65"
      },
      "outputs": [],
      "source": [
        "from thinkstats import Pdf\n",
        "\n",
        "domain = np.min(birth_weights), np.max(birth_weights)\n",
        "kde_birth_weights = Pdf(kde, domain, name=\"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0023131",
      "metadata": {
        "id": "e0023131"
      },
      "source": [
        "`Pdf` provides a `plot` method we can use to compare the estimated PDF of the sample to the PDF of a normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d79028e",
      "metadata": {
        "id": "4d79028e"
      },
      "outputs": [],
      "source": [
        "pdf_model.plot(ls=\":\", color=\"gray\")\n",
        "kde_birth_weights.plot()\n",
        "\n",
        "decorate(xlabel=\"Birth weight (pounds)\", ylabel=\"Density\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eaf2160",
      "metadata": {
        "id": "2eaf2160"
      },
      "source": [
        "Kernel density estimation makes it possible to compare the distribution of a dataset to a theoretical model, and for some audiences, this is a good way to visualize the comparison.\n",
        "But for audiences that are familiar with CDFs, comparing CDFs is often better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9890ea3b",
      "metadata": {
        "id": "9890ea3b"
      },
      "source": [
        "## The Distribution Framework\n",
        "\n",
        "At this point we have a complete set of ways to represent distributions: PMFs, CDFs, and PDFs\n",
        "The following figure shows these representations and the transitions from one to another.\n",
        "For example, if we have a `Pmf`, we can use the `cumsum` function to compute the cumulative sum of the probabilities and get a `Cdf` that represents the same distribution.\n",
        "\n",
        "<img width=\"400\" src=\"https://github.com/AllenDowney/ThinkStats/raw/v3/figs/distribution_framework.png\">\n",
        "\n",
        "To demonstrate these transitions, we'll use a new dataset that \"contains the time of birth, sex, and birth weight for each of 44 babies born in one 24-hour period at a Brisbane, Australia, hospital,\" according to the description.\n",
        "Instructions for downloading the data are in the notebook for this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460e5444",
      "metadata": {
        "tags": [],
        "id": "460e5444"
      },
      "source": [
        "According to the information in the file\n",
        "\n",
        "> Source: Steele, S. (December 21, 1997), \"Babies by the Dozen for Christmas:\n",
        "24-Hour Baby Boom,\" _The Sunday Mail_ (Brisbane), p. 7.\n",
        ">\n",
        "> STORY BEHIND THE DATA:\n",
        "Forty-four babies -- a new record -- were born in one 24-hour period at\n",
        "the Mater Mothers' Hospital in Brisbane, Queensland, Australia, on\n",
        "December 18, 1997.  For each of the 44 babies, _The Sunday Mail_\n",
        "recorded the time of birth, the sex of the child, and the birth weight\n",
        "in grams.\n",
        ">\n",
        "> Additional information about this dataset can be found in the \"Datasets\n",
        "and Stories\" article \"A Simple Dataset for Demonstrating Common\n",
        "Distributions\" in the _Journal of Statistics Education_ (Dunn 1999).\n",
        ">\n",
        "> Downloaded from <https://jse.amstat.org/datasets/babyboom.txt>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209b7e67",
      "metadata": {
        "tags": [],
        "id": "209b7e67"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/babyboom.dat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3517d0",
      "metadata": {
        "id": "7c3517d0"
      },
      "source": [
        "We can read the data like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4c6176",
      "metadata": {
        "id": "1d4c6176"
      },
      "outputs": [],
      "source": [
        "from thinkstats import read_baby_boom\n",
        "\n",
        "boom = read_baby_boom()\n",
        "boom.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9cc296d",
      "metadata": {
        "id": "e9cc296d"
      },
      "source": [
        "The `minutes` column records \"the number of minutes since midnight for each birth\".\n",
        "So we can use the `diff` method to compute the interval between each successive birth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942f38eb",
      "metadata": {
        "id": "942f38eb"
      },
      "outputs": [],
      "source": [
        "diffs = boom[\"minutes\"].diff().dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab56d42",
      "metadata": {
        "id": "fab56d42"
      },
      "source": [
        "If births happen with equal probability during any minute of the day, we expect these intervals to follow an exponential distribution.\n",
        "In reality, that assumption is not precisely true, but the exponential distribution might still be a good model for the data.\n",
        "\n",
        "To find out, we'll start by making a `Pmf` that represents the distribution of intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee30688b",
      "metadata": {
        "id": "ee30688b"
      },
      "outputs": [],
      "source": [
        "pmf_diffs = Pmf.from_seq(diffs, name=\"data\")\n",
        "pmf_diffs.bar(width=1)\n",
        "\n",
        "decorate(xlabel=\"Interval (minutes)\", ylabel=\"PMF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdcd639f",
      "metadata": {
        "id": "cdcd639f"
      },
      "source": [
        "Then we can use `make_cdf` to compute the cumulative probabilities and store them in a `Cdf` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4466e8cc",
      "metadata": {
        "id": "4466e8cc"
      },
      "outputs": [],
      "source": [
        "cdf_diffs = pmf_diffs.make_cdf()\n",
        "cdf_diffs.step()\n",
        "\n",
        "decorate(xlabel=\"Interval (minutes)\", ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8960e286",
      "metadata": {
        "id": "8960e286"
      },
      "source": [
        "The `Pmf` and `Cdf` are equivalent in the sense that if we are given either one, we can compute the other.\n",
        "To demonstrate, we'll use the `make_pmf` method, which computes the differences between successive probabilities in a `Cdf` and returns a `Pmf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9367a75f",
      "metadata": {
        "id": "9367a75f"
      },
      "outputs": [],
      "source": [
        "pmf_diffs2 = cdf_diffs.make_pmf()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db091dd4",
      "metadata": {
        "id": "db091dd4"
      },
      "source": [
        "The result should be identical to the original `Pmf`, but there might be small floating-point errors.\n",
        "We can use `allclose` to check that the result is close to the original `Pmf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57be0167",
      "metadata": {
        "id": "57be0167"
      },
      "outputs": [],
      "source": [
        "np.allclose(pmf_diffs, pmf_diffs2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc925f4",
      "metadata": {
        "id": "dfc925f4"
      },
      "source": [
        "And it is.\n",
        "\n",
        "From a `Pmf`, we can estimate a density function by calling `gaussian_kde` with the probabilities from the `Pmf` as weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb28634",
      "metadata": {
        "id": "fcb28634"
      },
      "outputs": [],
      "source": [
        "kde = gaussian_kde(pmf_diffs.qs, weights=pmf_diffs.ps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f60a7db",
      "metadata": {
        "id": "2f60a7db"
      },
      "source": [
        "To plot the results, we can use `kde` to make a `Pdf` object, and call the `plot` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a9a473",
      "metadata": {
        "id": "a8a9a473"
      },
      "outputs": [],
      "source": [
        "domain = np.min(pmf_diffs.qs), np.max(pmf_diffs.qs)\n",
        "kde_diffs = Pdf(kde, domain=domain, name=\"estimated density\")\n",
        "\n",
        "kde_diffs.plot(ls=\":\", color=\"gray\")\n",
        "decorate(xlabel=\"Interval (minutes)\", ylabel=\"Density\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff7e136",
      "metadata": {
        "id": "8ff7e136"
      },
      "source": [
        "To see whether the estimated density follows an exponential model, we can make an `ExponentialCdf` with the same mean as the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fe533b",
      "metadata": {
        "id": "21fe533b"
      },
      "outputs": [],
      "source": [
        "from thinkstats import ExponentialCdf\n",
        "\n",
        "m = diffs.mean()\n",
        "lam = 1 / m\n",
        "cdf_model = ExponentialCdf(lam, name=\"exponential CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c44e2e63",
      "metadata": {
        "id": "c44e2e63"
      },
      "source": [
        "Heres what it looks like compared to the CDF of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe493a82",
      "metadata": {
        "id": "fe493a82"
      },
      "outputs": [],
      "source": [
        "cdf_model.plot(ls=\":\", color=\"gray\")\n",
        "cdf_diffs.step()\n",
        "\n",
        "decorate(xlabel=\"Interval (minutes)\", ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323b1e1b",
      "metadata": {
        "id": "323b1e1b"
      },
      "source": [
        "The exponential model fits the CDF of the data well."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51583008",
      "metadata": {
        "id": "51583008"
      },
      "source": [
        "Given an `ExponentialCdf`, we can use `make_cdf` to **discretize** the CDF -- that is, to make a discrete approximation by evaluating the CDF at a sequence of equally spaced quantities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6993364d",
      "metadata": {
        "id": "6993364d"
      },
      "outputs": [],
      "source": [
        "qs = np.linspace(0, 160)\n",
        "discrete_cdf_model = cdf_model.make_cdf(qs)\n",
        "discrete_cdf_model.step(color=\"gray\")\n",
        "\n",
        "decorate(xlabel=\"Interval (minutes)\", ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed63815d",
      "metadata": {
        "id": "ed63815d"
      },
      "source": [
        "Finally, to get from a discrete CDF to a continuous CDF, we can interpolate between the steps, which is what we see if we use the `plot` method instead of the `step` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf96cbce",
      "metadata": {
        "id": "bf96cbce"
      },
      "outputs": [],
      "source": [
        "discrete_cdf_model.plot(color=\"gray\")\n",
        "\n",
        "decorate(xlabel=\"Interval (minutes)\", ylabel=\"CDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdb6bc7c",
      "metadata": {
        "id": "bdb6bc7c"
      },
      "source": [
        "Finally, a PDF is the derivative of a continuous CDF, and a CDF is the integral of a PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e5603e",
      "metadata": {
        "tags": [],
        "id": "f4e5603e"
      },
      "source": [
        "To demonstrate, we can use SymPy to define the CDF of an exponential distribution and compute its derivative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e749a9",
      "metadata": {
        "tags": [],
        "id": "54e749a9"
      },
      "outputs": [],
      "source": [
        "import sympy as sp\n",
        "\n",
        "x = sp.Symbol(\"x\", real=True, positive=True)\n",
        " = sp.Symbol(\"\", real=True, positive=True)\n",
        "\n",
        "cdf = 1 - sp.exp(- * x)\n",
        "cdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c302237",
      "metadata": {
        "tags": [],
        "id": "7c302237"
      },
      "outputs": [],
      "source": [
        "pdf = sp.diff(cdf, x)\n",
        "pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f9e807",
      "metadata": {
        "tags": [],
        "id": "c2f9e807"
      },
      "source": [
        "And if we integrate the result, we get the CDF back -- although we lose the constant of integration in the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08aa791",
      "metadata": {
        "tags": [],
        "id": "f08aa791"
      },
      "outputs": [],
      "source": [
        "sp.integrate(pdf, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b16b7bad",
      "metadata": {
        "id": "b16b7bad"
      },
      "source": [
        "This example shows how we use `Pmf`, `Cdf`, and `Pdf` objects to represent PMFs, CDFs, and PDFs, and demonstrates the process for converting from each to the others."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d0b0db",
      "metadata": {
        "id": "83d0b0db"
      },
      "source": [
        "## Glossary\n",
        "\n",
        "-   **continuous:** A quantity is continuous if it can have any value in a range on the number line. Most things we measure in the world -- like weight, distance, and time -- are continuous.\n",
        "\n",
        "\n",
        "-   **discrete:** A quantity is discrete if it can have a limited set of values, like integers or categories. Exact counts are discrete, as well as categorical variables.\n",
        "\n",
        "\n",
        "-   **probability density function (PDF)**: A function that shows how density (not probability) is spread across the values of a continuous variable. The area under the PDF within an interval gives the probability that the variable falls in that interval range.\n",
        "\n",
        "\n",
        "-   **probability density**: The value of a PDF at a specific point; it's not a probability itself, but it can be used to compute a probability.\n",
        "\n",
        "\n",
        "-   **kernel density estimation (KDE)**: A method for estimating a PDF based on a sample.\n",
        "\n",
        "\n",
        "-   **discretize**: To approximate a continuous quantity by dividing its range into discrete levels or categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a21248f4",
      "metadata": {
        "id": "a21248f4"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16858dd0",
      "metadata": {
        "id": "16858dd0"
      },
      "source": [
        "### Exercise 6.1\n",
        "\n",
        "In World Cup soccer (football), suppose the time until the first goal is well modeled by an exponential distribution with rate `lam=2.5` goals per game.\n",
        "Make an `ExponentialPdf` to represent this distribution and use `area_under` to compute the probability that the time until the first goal is less than half of a game.\n",
        "Then use an `ExponentialCdf` to compute the same probability and check that the results are consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d4de90",
      "metadata": {
        "id": "80d4de90"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08933d1",
      "metadata": {
        "id": "d08933d1"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae9e038",
      "metadata": {
        "id": "7ae9e038"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3029643",
      "metadata": {
        "id": "d3029643"
      },
      "source": [
        "Use `ExponentialPdf` to compute the probability the first goal is scored in the second half of the game.\n",
        "Then use an `ExponentialCdf` to compute the same probability and check that the results are consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9890bed0",
      "metadata": {
        "id": "9890bed0"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d82610",
      "metadata": {
        "id": "50d82610"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4c52fe0",
      "metadata": {
        "id": "a4c52fe0"
      },
      "source": [
        "### Exercise 6.2\n",
        "\n",
        "In order to join Blue Man Group, you have to be male between 510 and 61, which is roughly 178 to 185 centimeters.\n",
        "Let's see what fraction of the male adult population in the United States meets this requirement.\n",
        "\n",
        "The heights of male participants in the BRFSS are well modeled by a normal distribution with mean 178 cm and standard deviation 7 cm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cb2c493",
      "metadata": {
        "tags": [],
        "id": "7cb2c493"
      },
      "outputs": [],
      "source": [
        "download(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/CDBRFS08.ASC.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6431e26c",
      "metadata": {
        "id": "6431e26c"
      },
      "outputs": [],
      "source": [
        "from thinkstats import read_brfss\n",
        "\n",
        "brfss = read_brfss()\n",
        "male = brfss.query(\"sex == 1\")\n",
        "heights = male[\"htm3\"].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed41b925",
      "metadata": {
        "id": "ed41b925"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import trimboth\n",
        "\n",
        "trimmed = trimboth(heights, 0.01)\n",
        "m, s = np.mean(trimmed), np.std(trimmed)\n",
        "m, s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd36059",
      "metadata": {
        "id": "edd36059"
      },
      "source": [
        "Here's a `NormalCdf` object that represents a normal distribution with the same mean and standard deviation as the trimmed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3533b0",
      "metadata": {
        "id": "fe3533b0"
      },
      "outputs": [],
      "source": [
        "from thinkstats import NormalCdf\n",
        "\n",
        "cdf_normal_model = NormalCdf(m, s, name='normal model')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b01929f",
      "metadata": {
        "id": "6b01929f"
      },
      "source": [
        "And here's how it compares to the CDF of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ca42c9",
      "metadata": {
        "id": "76ca42c9"
      },
      "outputs": [],
      "source": [
        "cdf_height = Cdf.from_seq(heights, name=\"data\")\n",
        "cdf_normal_model.plot(ls=\":\", color=\"gray\")\n",
        "cdf_height.step()\n",
        "\n",
        "xlim = [140, 210]\n",
        "decorate(xlabel=\"Height (cm)\", ylabel=\"CDF\", xlim=xlim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e013acb",
      "metadata": {
        "id": "4e013acb"
      },
      "source": [
        "Use `gaussian_kde` to make a `Pdf` that approximates the PDF of male height.\n",
        "Hint: Investigate the `bw_method` argument, which can be used to control the smoothness of the estimated density.\n",
        "Plot the estimated density and compare it to a `NormalPdf` with mean `m` and standard deviation `s`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d3eeac",
      "metadata": {
        "id": "66d3eeac"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec3f886",
      "metadata": {
        "id": "dec3f886"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c814eb",
      "metadata": {
        "id": "80c814eb"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61eaec6",
      "metadata": {
        "id": "d61eaec6"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53604a1a",
      "metadata": {
        "id": "53604a1a"
      },
      "source": [
        "Use a `NormalPdf` and `area_under` to compute the fraction of people in the normal model that are between 178 and 185 centimeters.\n",
        "Use a `NormalCdf` to compute the same fraction, and check that the results are consistent.\n",
        "Finally, use the empirical `Cdf` of the data to see what fraction of people in the dataset are in the same range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0485114",
      "metadata": {
        "id": "e0485114"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18db45b3",
      "metadata": {
        "id": "18db45b3"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0ad75b",
      "metadata": {
        "id": "5e0ad75b"
      },
      "outputs": [],
      "source": [
        "# Solution goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27da3a4",
      "metadata": {
        "tags": [],
        "id": "e27da3a4"
      },
      "source": [
        "[Think Stats: Exploratory Data Analysis in Python, 3rd Edition](https://allendowney.github.io/ThinkStats/index.html)\n",
        "\n",
        "Copyright 2024 [Allen B. Downey](https://allendowney.com)\n",
        "\n",
        "Code license: [MIT License](https://mit-license.org/)\n",
        "\n",
        "Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}